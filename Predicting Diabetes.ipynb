{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|label|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[0.03807590643342...|151.0|206.07345904776457|\n",
      "|[-0.0018820165277...| 75.0| 68.11130074493127|\n",
      "|[0.08529890629667...|141.0|176.84041283471993|\n",
      "|[-0.0890629393522...|206.0|166.85823029221254|\n",
      "|[0.00538306037424...|135.0|128.45256889870686|\n",
      "|[-0.0926954778032...| 97.0|106.33594406619089|\n",
      "|[-0.0454724779400...|138.0| 73.98067035208017|\n",
      "|[0.06350367559056...| 63.0|118.92115653222096|\n",
      "|[0.04170844488444...|110.0|158.82436723778147|\n",
      "|[-0.0709002470971...|310.0|213.58516459582046|\n",
      "|[-0.0963280162542...|101.0| 97.14573768173099|\n",
      "|[0.02717829108036...| 69.0| 95.26108457593733|\n",
      "|[0.01628067572730...|179.0|115.05862144632293|\n",
      "|[0.00538306037424...|185.0|164.62484148553486|\n",
      "|[0.04534098333546...|118.0|103.05032974805701|\n",
      "|[-0.0527375548420...|171.0|177.10280850293879|\n",
      "|[-0.0055145549788...|166.0|211.70553577361474|\n",
      "|[0.0707687524926,...|144.0| 182.8279858522345|\n",
      "|[-0.0382074010379...| 97.0| 147.9704592445661|\n",
      "|[-0.0273097856849...|168.0|123.98114508514756|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "MSE = 2859.6954229074618\n",
      "RMSE = 53.47612011830572\n",
      "R-squared = 0.06822819279431158\n",
      "MAE = 43.276527704501326\n",
      "Explained variance = 5929.884896910383\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "4> Predicting Diabetes using LinearRegression from MLib (Machine Learning library from Spark) \n",
    "\n",
    "This Diabetes dataset downloaded from Sklearn has ten baseline variables, age, sex, body mass index, average blood \n",
    "pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the \n",
    "response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "A fasting blood sugar level less than 100 mg/dL (5.6 mmol/L) is normal. A fasting blood sugar level from 100 to \n",
    "125 mg/dL (5.6 to 6.9 mmol/L) is considered prediabetes. If it's 126 mg/dL (7 mmol/L) or higher on two separate \n",
    "tests, you have diabetes. Oral glucose tolerance test.\n",
    "'''\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "# Import and clean data. Pyspark uses its own type system and unfortunately it doesn't deal with numpy well. \n",
    "# It works with python types though. So you need to manually convert the numpy.float64 to float.\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_features= []\n",
    "\n",
    "# Spark uses breeze under the hood for high performance Linear Algebra in Scala. In Spark, MLlib and other \n",
    "# ML algorithms depends on org.apache.spark.mllib.libalg.Vector type which is rather dense or sparse.\n",
    "\n",
    "for feature_list in diabetes.data:\n",
    "    temp= [float(i) for i in feature_list]\n",
    "    diabetes_features.append(Vectors.dense(temp))\n",
    "    \n",
    "diabetes_target = [float(i) for i in diabetes.target]\n",
    "features_and_predictions = list(zip(diabetes_target, diabetes_features))\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"LinearRegression_Diabetes\")\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.createDataFrame(features_and_predictions, [\"label\", \"features\"])\n",
    "\n",
    "# Only max iterations is set. We will set parameters for the algorithm after ParamGridSearch\n",
    "lr = LinearRegression(maxIter=10)\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "LR_model = tvs.fit(df)\n",
    "\n",
    "# Make predictions on test data. LR_model is the model with combination\n",
    "# of parameters that performed best.\n",
    "\n",
    "LR_model.transform(df)\\\n",
    "    .select(\"features\",\"label\", \"prediction\").show()\n",
    "\n",
    "Dataframe = LR_model.transform(df)\\\n",
    "    .select(\"label\", \"prediction\")\n",
    "\n",
    "# Metrics object needs to have an RDD of (prediction, observation) pairs.\n",
    "# Convert the dataframe object to an RDD\n",
    "\n",
    "valuesAndPreds = Dataframe.rdd.map(tuple)\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = RegressionMetrics(valuesAndPreds)\n",
    "\n",
    "# Squared Error\n",
    "print(\"MSE = %s\" % metrics.meanSquaredError)\n",
    "print(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n",
    "\n",
    "# R-squared\n",
    "print(\"R-squared = %s\" % metrics.r2)\n",
    "\n",
    "# Mean absolute error\n",
    "print(\"MAE = %s\" % metrics.meanAbsoluteError)\n",
    "\n",
    "# Explained variance\n",
    "print(\"Explained variance = %s\" % metrics.explainedVariance)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
